{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qNJ_JSlErv"
   },
   "source": [
    "# Lab 00 - A - Data Analysis In Python - First Steps\n",
    "\n",
    "Machine learning and data analysis (that is usually also a pre-step for learning) deal with data. Thererefore we need tools to manipulate it and extract the information we want. In the Python environment there are two very useful packages for this: [`numpy`](https://numpy.org/doc/1.19/) and [`pandas`](https://pandas.pydata.org/docs/reference/index.html#api).\n",
    "\n",
    "In this lab, we will take the first steps into using these packages and see some of their functionalities. These will be needed throughout the course. Both packages contain many useful functionalities, of which we will introduce only a few. To find out more about the other functionalities, the documentations, **Google** and **StackOverflow** are your best friends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hx4v3hy-fnu9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9236/1601004011.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\iml\\IML.HUJI\\lab\\..\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Imports and settings for plotting of graphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_subplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# Load commonly used imports (such as numpy and pandas) and several utils functions that \n",
    "# are used thoughout different labs and code examples\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asLx3ujI09-B"
   },
   "source": [
    "# Numpy - The Basics\n",
    "\n",
    "Let us start with numpy. This package supports vector, matrix and tensor operations over numerical (but not just) data. It is very comfortable and much faster than `for` loops and classic `list` manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPwJrL1Bc84L"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "There are multiple ways to create an array. We can create it from an existing list, load it from a file or generate a new array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wL4cbVc-pGZ9",
    "outputId": "e5e90a34-4000-4d85-8672-7559f6ecaf6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6   2   8   4   5  10   7 143   9  10]\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "array_1D = np.array([6, 2, 8, 4, 5, 10, 7, 143, 9, 10])\n",
    "print(array_1D)\n",
    "print(array_1D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt6ZB5FG1p2d",
    "outputId": "b3f5bdbf-9547-485a-bff1-29e07aecc6aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  10   20   30   40]\n",
      " [ 100  200  300  400]\n",
      " [1000 2000 3000 4000]]\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "array_2D = np.array(\n",
    "    [[10, 20, 30, 40], \n",
    "     [100, 200, 300, 400], \n",
    "     [1000, 2000, 3000, 4000]])\n",
    "print(array_2D)\n",
    "print(array_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICxIiGg92M7C",
    "outputId": "5c5f5333-af82-4e07-f836-202fddf7a8fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  10   20   30   40]\n",
      "  [ 100  200  300  400]\n",
      "  [1000 2000 3000 4000]]\n",
      "\n",
      " [[  11   21   31   41]\n",
      "  [ 101  201  301  401]\n",
      "  [1001 2001 3001 4001]]]\n",
      "(2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "array_3D = np.array(\n",
    "    [[[10, 20, 30, 40], [100, 200, 300, 400], [1000, 2000, 3000, 4000]],\n",
    "    [[11, 21, 31, 41], [101, 201, 301, 401], [1001, 2001, 3001, 4001]]])\n",
    "print(array_3D)\n",
    "print(array_3D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8ikdeRnpupl"
   },
   "source": [
    "Using `numpy`'s functions for creating new arrays requires specifying the shape of the desired output array. This is an n-array tuple specifying the sizes of the different dimensions. \n",
    "\n",
    "*   Specifying the shape `(3)` will create a 1D array with 3 entries.\n",
    "*   Specifying the shape `(10, 3)` will create a 2D matrix with 10 rows and 3 columns.\n",
    "*   Specifying the shape `(10, 28, 28)` will create a 3D matrix (a tensor) which we can think of in the following manner: it is an object holding 10 2D matrices of size 28x28.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZNN-w4B2vsy",
    "outputId": "5d668f56-aae6-42cc-c13c-b6cce1b0a1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Initalize arrays with built-in numpy functions\n",
    "zeros_3D = np.zeros((4, 5, 2)) # Create a 3D arrays of 0's\n",
    "ones_2D = np.ones((4, 5)) # Create a 2D arrays of 1's\n",
    "print(zeros_3D)\n",
    "print(ones_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ke7ltD8qt8I",
    "outputId": "9de4ca81-d090-47e7-bbad-a7cd9dea2d5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(50) # Create the vector [0, 1, 2, 3, 4, .. , 48, 49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8tf4cd4q4oE",
    "outputId": "91be65fe-ab25-455b-9fc8-8a455b07104c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 19, 45],\n",
       "       [47, 24, 18]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector of random integers from 5 to 50, with shape (2, 3)\n",
    "np.random.randint(5, 50, (2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THE5lTeTrN4w"
   },
   "source": [
    "There are many other functions such as `np.full`, `np.eye`, `np.random.uniform`, etc. Next, let us load an existsing dataset into a numpy array. This specific dataset represents images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "O3ZsPny03qmZ",
    "outputId": "3d22fab1-7cb1-4180-a1c2-a5c1528f6de5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array = np.loadtxt(open(\"../datasets/MNIST_Images.csv\", \"rb\"), delimiter=\",\").reshape(-1, 28, 28)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'px' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9236/1672309730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'px' is not defined"
     ]
    }
   ],
   "source": [
    "px.imshow(img_array[0]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F10jW-AO8PdQ"
   },
   "source": [
    "## Array indexing and slicing\n",
    "\n",
    "A great strength of `numpy` is the ease in subsetting an array to retrieve only specific parts of it. We do so by indexing and slicing the arrays. For 1D arrays these operations are very similar to those over lists.  For arrays of higher dimensions, we use a comma to separate the slicing of each dimension. For example, accessing an element in the array `arr` in the first row and second column is done by: `arr[0, 1]` (recall indexing in python begins from zero). To select only the second column, over all rows write: `arr[:, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KZJfKZ-_67Yk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 1st element\n",
      "11\n",
      "\n",
      "Select all the elements from 1st to 4th element\n",
      "[11 12 13 14]\n",
      "\n",
      "Select elements [1, 4]\n",
      "[11 14]\n",
      "7\n",
      "\n",
      "Print random array\n",
      "[[32 38 39 24 43 31 23 19 32 13 25 38 27 44 10 34 45 13 33 37]\n",
      " [12 42 49 34 34 40 43 28 34 17 44  9 43 25 30 36 25 28 48 12]\n",
      " [41 30 25  7 34 16 17  9 12  8 17 15 48  8 48 31 35 30 18 43]\n",
      " [ 6 15 33 44 13 12 23 13 33 28 32  8 10 11 19 31 33 23  6 14]\n",
      " [31 46 30 26 19 36 17 26 25 36 19 29 26 44 48 10 33 21 46 49]\n",
      " [38 24 43 36 27 17 33 38 17 19 22 43  7 20  8  6 43  8 37 41]\n",
      " [14  6 43 27  7 29 18 30 14 32  5 45 42 33 33 36  7 26 29 35]\n",
      " [15 46 17  5 10 49 18 14 37 46 13 12 27 16 39  9 13 38  7 45]\n",
      " [ 6  8  6 10 22 29 36 37 27 34 25 23 39 45 11 25 28 35 31 21]\n",
      " [48 27 29 34 47 36 27 25 46 36 45 18 20 34  9 13 17 37 15  9]]\n",
      "\n",
      "Select from 3rd row to 5th, all the columns\n",
      "[[41 30 25  7 34 16 17  9 12  8 17 15 48  8 48 31 35 30 18 43]\n",
      " [ 6 15 33 44 13 12 23 13 33 28 32  8 10 11 19 31 33 23  6 14]\n",
      " [31 46 30 26 19 36 17 26 25 36 19 29 26 44 48 10 33 21 46 49]]\n",
      "\n",
      "Select from 3rd row to 5th, columns 1 and 2\n",
      "[[30 25]\n",
      " [15 33]\n",
      " [46 30]]\n",
      "\n",
      "Select from 3rd row to 5th, columns 3, 5, 6, and  11\n",
      "[[ 7 16 17 15]\n",
      " [44 12 23  8]\n",
      " [26 36 17 29]]\n"
     ]
    }
   ],
   "source": [
    "array_1D = np.array([10, 11, 12, 13, 14, 15, 16])\n",
    "# Select 1st element\n",
    "print(\"Select 1st element\") \n",
    "print(array_1D[1])\n",
    "\n",
    "# Select all the elements from 1st to 4th element\n",
    "print(\"\\nSelect all the elements from 1st to 4th element\") \n",
    "print(array_1D[1:5])\n",
    "\n",
    "# Select elements [1, 4]\n",
    "print(\"\\nSelect elements [1, 4]\")\n",
    "print(array_1D[[1, 4]])\n",
    "\n",
    "\n",
    "array_2D = np.array([[1, 2, 3, 4],\n",
    "                     [5, 6, 7, 8],\n",
    "                     [9, 10, 11, 12],\n",
    "                     [13, 14, 15, 16],\n",
    "                     [17, 18, 19, 20]])\n",
    "# Select 1st row, 2nd column  \n",
    "print(array_2D[1, 2])\n",
    "\n",
    "\n",
    "randint_2D = np.random.randint(5, 50, (10, 20))\n",
    "print(\"\\nPrint random array\")\n",
    "print(randint_2D)\n",
    "\n",
    "# Select from 3rd row to 5th, all the columns\n",
    "print(\"\\nSelect from 3rd row to 5th, all the columns\")\n",
    "print(randint_2D[2:5, :])\n",
    "\n",
    "# Select from 3rd row to 5th, columns 1 and 2\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 1 and 2\")\n",
    "print(randint_2D[2:5, 1:3])\n",
    "\n",
    "# Select from 3d row to 5th, columns 3, 5, 6, and  11\n",
    "print(\"\\nSelect from 3rd row to 5th, columns 3, 5, 6, and  11\")\n",
    "print(randint_2D[2:5, [3, 5, 6, 11]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn4PwoBerrJl"
   },
   "source": [
    "## Matrix Operations\n",
    "Another strength of the `numpy` package is that all matrix operations you can think of (and even more) are already implemented. For example, element-wise addition of scalar, multiplication, powering up a matrix, log-transformations and much more.\n",
    "\n",
    "As `numpy` overloads the different mathematical operators, it is easy to write mathematical expressions over 2 (or more) vectors/matrices, such as summing or multiplying and also comparing their elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4OXpnPKiLbg",
    "outputId": "9d066e26-47b4-4db3-971d-5e3c4ae6a1d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]\n",
      " [25 26 27 28 29 30 31 32]]\n",
      "\n",
      "\n",
      "A + 1:\n",
      "[[ 2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17]\n",
      " [18 19 20 21 22 23 24 25]\n",
      " [26 27 28 29 30 31 32 33]]\n",
      "\n",
      "2 * A:\n",
      "[[ 2  4  6  8 10 12 14 16]\n",
      " [18 20 22 24 26 28 30 32]\n",
      " [34 36 38 40 42 44 46 48]\n",
      " [50 52 54 56 58 60 62 64]]\n",
      "\n",
      "A*A*A:\n",
      "[[    1     8    27    64   125   216   343   512]\n",
      " [  729  1000  1331  1728  2197  2744  3375  4096]\n",
      " [ 4913  5832  6859  8000  9261 10648 12167 13824]\n",
      " [15625 17576 19683 21952 24389 27000 29791 32768]]\n",
      "\n",
      "log(A):\n",
      "[[0.         0.69314718 1.09861229 1.38629436 1.60943791 1.79175947\n",
      "  1.94591015 2.07944154]\n",
      " [2.19722458 2.30258509 2.39789527 2.48490665 2.56494936 2.63905733\n",
      "  2.7080502  2.77258872]\n",
      " [2.83321334 2.89037176 2.94443898 2.99573227 3.04452244 3.09104245\n",
      "  3.13549422 3.17805383]\n",
      " [3.21887582 3.25809654 3.29583687 3.33220451 3.36729583 3.40119738\n",
      "  3.4339872  3.4657359 ]]\n",
      "\n",
      "A Transpose:\n",
      "<built-in method transpose of numpy.ndarray object at 0x000002D48EB4DB70>\n",
      "\n",
      " A > 10:\n",
      "[[False False False False False False False False]\n",
      " [False False  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True]\n",
      " [ True  True  True  True  True  True  True  True]]\n",
      "A\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "\n",
      "B\n",
      "[[2 2 8]\n",
      " [7 2 6]]\n",
      "\n",
      "A+B:\n",
      "[[ 2  3 10]\n",
      " [10  6 11]]\n",
      "\n",
      " A * B (element-wise multiplication):\n",
      "[[ 0  2 16]\n",
      " [21  8 30]]\n",
      "\n",
      " AB (matrix multiplication):\n",
      "[[18 14]\n",
      " [54 59]]\n",
      "\n",
      "A > B\n",
      "[[False False False]\n",
      " [False  True False]]\n"
     ]
    }
   ],
   "source": [
    "# Operations on 1 matrix\n",
    "A = np.arange(1, 33).reshape(4, 8) # Create an array of numbers from 1 ot 32, and then make a 2d array of 4 rows to 8 columns\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nA + 1:\")\n",
    "print(A + 1)\n",
    "print(\"\\n2 * A:\")\n",
    "print(2 * A)\n",
    "print(\"\\nA*A*A:\")\n",
    "print(np.power(A, 3))\n",
    "print(\"\\nlog(A):\")\n",
    "print(np.log(A))\n",
    "print(\"\\nA Transpose:\")\n",
    "print(A.transpose) # also np.transpose(A) and A.T are valid syntaxes\n",
    "print(\"\\n A > 10:\")\n",
    "print(A > 10)\n",
    "\n",
    "# Operations on 2 matrices\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "B = np.random.randint(1, 10, (2, 3))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nA+B:\")\n",
    "print(A + B) # Equivalent to np.add(a_array, b_array)\n",
    "print(\"\\n A * B (element-wise multiplication):\")\n",
    "print(np.multiply(A, B))\n",
    "print(\"\\n AB (matrix multiplication):\")\n",
    "print(A @ B.T) # Equivalent to np.dot(a_array, b_array)\n",
    "\n",
    "print(\"\\nA > B\")\n",
    "print(A > B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBGJkM0PvWPC"
   },
   "source": [
    "For many `numpy` operations we can specify the `axis` over which to perform the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXznlk6aiNP3",
    "outputId": "09591fed-8ec1-44b6-e98e-af7ca2e0824e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concatenate 2 arrays by the rows:\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [2 2 8]\n",
      " [7 2 6]]\n",
      "\n",
      "Concatenate 2 arrays by the columns:\n",
      "[[0 1 2 2 2 8]\n",
      " [3 4 5 7 2 6]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate matrices\n",
    "print(\"\\nConcatenate 2 arrays by the rows:\")\n",
    "print(np.concatenate((A, B), axis = 0)) # Concatenate rows - look at the shape\n",
    "print(\"\\nConcatenate 2 arrays by the columns:\")\n",
    "print(np.concatenate((A, B), axis = 1)) # Concatenate columns - look at the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4O_Kvftueqx"
   },
   "source": [
    "##  Basic Statistics\n",
    "\n",
    "You can easily calculate a lot of basic statistics from an array, such as the sum, mean, variance, maximum, argmax, etc. All of these can be retrieved either over the entire array or over rows/columns.\n",
    "\n",
    "For each of these functions, you can get the statistic for: \n",
    "- the whole array: `np.stat(arr)`\n",
    "- by row: `np.stat(arr, axis = 1)`\n",
    "- by column: `np.stat(arr, axis = 0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2JhB4W8F_gdp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "\n",
      "\n",
      "Sum of the array\n",
      "15\n",
      "\n",
      "Sum of the array by column\n",
      "[3 5 7]\n",
      "\n",
      "Sum of the array by row\n",
      "[ 3 12]\n",
      "\n",
      "Max of each row\n",
      "[2 5]\n",
      "\n",
      "Max of each column\n",
      "[3 4 5]\n",
      "\n",
      "Average of all the array\n",
      "2.5\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics of a matrix\n",
    "A = np.arange(6).reshape([2, 3])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nSum of the array\")\n",
    "print(np.sum(A)) # Sum all the matrix (return a scalar)\n",
    "print(\"\\nSum of the array by column\")\n",
    "print(np.sum(A, axis = 0)) # Sum by column (return a vector)\n",
    "print(\"\\nSum of the array by row\")\n",
    "print(np.sum(A, axis = 1)) # Sum by row (return a vector)\n",
    "\n",
    "print(\"\\nMax of each row\")\n",
    "print(np.max(A, axis = 1)) # Max by column (return a vector)\n",
    "\n",
    "print(\"\\nMax of each column\")\n",
    "print(np.max(A, axis = 0)) # Max by row (return a vector)\n",
    "\n",
    "print(\"\\nAverage of all the array\")\n",
    "print(np.mean(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfF-hmlYw2fL"
   },
   "source": [
    "## Sampling From Distributions\n",
    "\n",
    "`numpy` provides a broad set of distributions to sample from. We will cover this in more depth in lab 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2HOVVWZw1vo",
    "outputId": "131b66b9-cb51-4c99-cfb9-be294c1cdf18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[12 13  4  8  4  2  2 14  5  7  6  4 12 14  3  3  9  5 14  4]\n",
      "\n",
      "\n",
      "The values that appear in the array\n",
      "[ 2  3  4  5  6  7  8  9 12 13 14]\n",
      "\n",
      "How many values are between [0, 5), [5, 10), [10, 15]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([8, 6, 6], dtype=int64), array([ 0,  5, 10, 15]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.randint(1, 15, size = 20)\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\n\\nThe values that appear in the array\")\n",
    "print(np.unique(A))\n",
    "print(\"\\nHow many values are between [0, 5), [5, 10), [10, 15]\")\n",
    "np.histogram(A, bins = [0, 5, 10, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOzh7VvbzFcJ"
   },
   "source": [
    "## Linear Algebra\n",
    "One of the most important mathematical fields in machine learning is linear algebra. You can perform many of these operations using `numpy`. You can calculate the eigenvectors of a matrix, or its inverse, the rank of the matrix and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57F3_BlBR-R3",
    "outputId": "a5c64b69-da33-451b-f54d-940f46c40cc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n",
      "\n",
      "\n",
      "Inverse of A\n",
      "[[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n",
      "\n",
      "\n",
      "B\n",
      "[[1 0 0]\n",
      " [0 2 0]\n",
      " [0 0 3]]\n",
      "\n",
      "eigenvalues, eigenvectors\n",
      "[1. 2. 3.] [[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "Rank of the matrix\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1., 2.], [3., 4.]])\n",
    "print(\"A\")\n",
    "print(A)\n",
    "print(\"\\n\\nInverse of A\")\n",
    "print(np.linalg.inv(A))\n",
    "\n",
    "B = np.diag((1, 2, 3))\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "eigvalues, eigvectors = np.linalg.eig(B)\n",
    "print(\"\\neigenvalues, eigenvectors\")\n",
    "print(eigvalues, eigvectors)\n",
    "\n",
    "print(\"\\nRank of the matrix\")\n",
    "print(np.linalg.matrix_rank(B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mLWs10U0dxW"
   },
   "source": [
    "## Reshaping\n",
    "\n",
    "You can change the shape of your array, with transpose, flattening, reshape, \n",
    "adding a new axis (see `np.newaxis`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qImJs4njAm43",
    "outputId": "3e70fefb-41fa-4c1c-d40e-1e1bb68e2590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "B\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "Flatten matrix\n",
      "[1 2 3 4 5 6]\n",
      "\n",
      "Transpose matrix\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"\\n\\nB\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\nFlatten matrix\")\n",
    "print(np.ravel(B))\n",
    "\n",
    "\n",
    "print(\"\\nTranspose matrix\")\n",
    "print(B.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwjDVpmk1Obt"
   },
   "source": [
    "## Sorting\n",
    "\n",
    "You can sort the matrix by row or by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "F7oe-5W4Vf2C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "[[ 3  6  1  4 10]\n",
      " [ 5  1  8  3 65]]\n",
      "\n",
      "\n",
      "Sort by row\n",
      "[[ 1  3  4  6 10]\n",
      " [ 1  3  5  8 65]]\n"
     ]
    }
   ],
   "source": [
    "B = np.array([[3, 6, 1, 4, 10], [5, 1, 8, 3, 65]])\n",
    "\n",
    "print(\"B\")\n",
    "print(B)\n",
    "\n",
    "print(\"\\n\\nSort by row\")\n",
    "print(np.sort(B, axis = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCsGskFR14ff"
   },
   "source": [
    "## Indexing By Condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSIflm-x13uf",
    "outputId": "6790bea5-8076-416c-a327-68ec2ad1c882"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[27 23 16 10]\n",
      " [20  1  4 19]\n",
      " [ 7 25  9 15]\n",
      " [15 11  8 29]\n",
      " [27 21  4  1]]\n",
      "\n",
      "Get the numbers that are greater than 5:\n",
      "[27 23 16 10 20 19  7 25  9 15 15 11  8 29 27 21]\n",
      "\n",
      "Get the numbers that are divisible by 4:\n",
      "[16 20  4  8  4]\n"
     ]
    }
   ],
   "source": [
    "A = np.random.randint(1, 30, (5, 4))\n",
    "print(\"A\")\n",
    "print(A)\n",
    "\n",
    "print(\"\\nGet the numbers that are greater than 5:\")\n",
    "print(A[A > 5])\n",
    "\n",
    "print(\"\\nGet the numbers that are divisible by 4:\")\n",
    "print(np.extract(np.mod(A, 4)==0, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZHrvwPc3xHl"
   },
   "source": [
    "## Let's practice!\n",
    "\n",
    "To get you a bit more accustomed to `numpy` you are encouraged to solve the following challenges. If you choose to not solve the following challenges, be sure to understand the solutions. Do not use loops or list comprehensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7IjEOuKwxbp"
   },
   "source": [
    "\n",
    "Write a program to create a `7x10` matrix that has `0` and `1` staggered:\n",
    "```\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "# 0 1 0 1 0 1 0\n",
    "# 1 0 1 0 1 0 1\n",
    "```\n",
    "Hint: use slice operations on different axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y_rAGqr2eknl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]]\n",
      "[[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      " [0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "staggered = np.zeros((7, 10))\n",
    "print(staggered)\n",
    "staggered[::2, 1::2] = 1\n",
    "print(staggered)\n",
    "staggered[1::2, ::2] = 1\n",
    "\n",
    "print(staggered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQdwsu47y0_u"
   },
   "source": [
    "Calculate the volume of a cylinder with the following diameters and lengths:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bNPOP0jU2On0"
   },
   "outputs": [],
   "source": [
    "diameters = np.array([1, 3, 5, 2, 4])\n",
    "lengths = np.array([10, 20, 3, 10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "C23xh9uX6Sbj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.85398163 141.37166941  58.90486225  31.41592654  62.83185307]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(np.power(diameters/2, 2)*lengths*np.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2RXomvKz1E2"
   },
   "source": [
    "Write a function that receives 2 vectors and returns their cartesian product:\n",
    "```\n",
    "def create_cartesian_product(vec1, vec2):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Sqo0fuvPmlsM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4]\n",
      " [1 5]\n",
      " [1 6]\n",
      " [1 7]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [2 6]\n",
      " [2 7]\n",
      " [3 4]\n",
      " [3 5]\n",
      " [3 6]\n",
      " [3 7]]\n"
     ]
    }
   ],
   "source": [
    "def cartesian_product(vec1, vec2):\n",
    "    # np.repeat([1, 2, 3], 4) -> [1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]\n",
    "    # np.tile([1, 2, 3], 4)   -> [1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
    "    return np.transpose(np.array([np.repeat(vec1, len(vec2)), np.tile(vec2, len(vec1))]))\n",
    "\n",
    "print(cartesian_product([1, 2, 3], [4, 5, 6, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fmVsBdq04UL"
   },
   "source": [
    "Given an array `a` and a number `n`, find the closest number to `n` in `a`:\n",
    "```\n",
    "def find_closest(a, n):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8dipzX5I8AE-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "def find_closest(a, n):\n",
    "  a = np.array(a)\n",
    "  return a[np.argmin(np.abs(a - n))]\n",
    "                     \n",
    "print(find_closest([1, 24, 12, 13, 14], 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_PKVyGO2dov"
   },
   "source": [
    "Check if the sudoku grid is valid:\n",
    "*   Check that each row contains all the numbers from 1 to 9\n",
    "*   Check that each column contains all the numbers from 1 to 9\n",
    "*   Check that each of the 9 non-overlapping `3x3` blocks composing grid contain 1 to 9\n",
    "\n",
    "You can assume it contains only integers and that the shape of the array is `9x9`\n",
    "```\n",
    "def check_sudoku(grid):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gZ5WPLiagvSI"
   },
   "outputs": [],
   "source": [
    "def is_1_to_9(array_):\n",
    "  # Return True if the array contains all the numbers from 1 to 9, False otherwise\n",
    "    return np.all(np.sort(array_, axis = None) == np.arange(1, 10))\n",
    "\n",
    "def check_sudoku(grid):\n",
    "    def check_block(coords_block):\n",
    "        return is_1_to_9(grid[coords_block[0]*3 : coords_block[0]*3+3, \n",
    "                              coords_block[1]*3 : coords_block[1]*3+3])\n",
    "\n",
    "    grid = np.array(grid)\n",
    "\n",
    "    # Check that the grid contains only 1 to 9\n",
    "    if (not is_1_to_9(np.unique(grid))):\n",
    "        return False\n",
    "\n",
    "    # Check that each line/column contains 1 to 9:\n",
    "    # Sort each column. We expect it to be\n",
    "    # [[1, 1, 1, 1, 1, 1, 1, 1, 1], [2, 2, 2, 2, 2, 2, 2, 2] ... [9, 9, 9, 9, 9, 9, 9, 9, 9]]\n",
    "    # Thus we expect the sums of the rows: 1*9, 2*9....\n",
    "    if  np.any(np.sum(np.sort(grid, axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "        return False\n",
    "\n",
    "    # Make the same for the columns\n",
    "    if np.any(np.sum(np.sort(grid.transpose(), axis = 0), axis = 1) != np.arange(1, 10)*9):\n",
    "        return False\n",
    "\n",
    "\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    # 0,0 0,0 0,0    0,1 0,1 0,1    0,2 0,2 0,2\n",
    "    #\n",
    "    #\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    # 1,0 1,0 1,0    1,1 1,1 1,1    1,2 1,2 1,2\n",
    "    #\n",
    "    #\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "    # 2,0 2,0 2,0    2,1 2,1 2,1    2,2 2,2 2,2\n",
    "\n",
    "\n",
    "    # For each block of 9, check if it contains all the numbers 1 to 9\n",
    "    blocks_are_valid = np.apply_along_axis(check_block, 1, cartesian_product([0, 1, 2], [0, 1, 2]))\n",
    "    return np.all(blocks_are_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmF3gn_pmP5X"
   },
   "source": [
    "Given a matrix, check if some row is a scalar multplication of another\n",
    "```\n",
    "def check_dependencies(matrix_):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IOxhEqkmhsRS"
   },
   "outputs": [],
   "source": [
    "def check_dependencies(matrix_):\n",
    "    def rows_are_dependent(indices):\n",
    "        if indices[0] == indices[1]:\n",
    "            return False\n",
    "        return np.unique(matrix_[indices[0],] / matrix_[indices[1],]).shape[0] == 1\n",
    "\n",
    "    return np.any(np.apply_along_axis(rows_are_dependent, 1,\n",
    "                                      cartesian_product(np.arange(matrix_.shape[0]), np.arange(matrix_.shape[0]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwL7kvvTkkxb"
   },
   "source": [
    "Write a function that gets a 1D array and check if there is no local extrema point in addition to the global one.\n",
    "```\n",
    "def have_an_extrema(array):\n",
    "  pass\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg12aIuikhh3"
   },
   "outputs": [],
   "source": [
    "def have_a_maxima(array):\n",
    "    argmax_arr = np.argmax(array[1:-1]) + 1\n",
    "    before_max_neg = np.all(array[:argmax_arr - 1] - array[1:argmax_arr] < 0)\n",
    "    after_max_neg = np.all(array[argmax_arr:-1] - array[argmax_arr + 1:] > 0)\n",
    "    return before_max_neg and after_max_neg\n",
    "\n",
    "def have_an_extrema(array):\n",
    "    # Check if it is a monotonic series\n",
    "    if np.unique(array[:-1] - array[1:]).shape[0] == 1: return True\n",
    "\n",
    "    # If there is a minimum, we can look for a maximum in the negated array\n",
    "    return have_a_maxima(array) or have_a_maxima(-array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf0Y2F8SlK6W"
   },
   "source": [
    "Note that instead of `array[:argmax_arr - 1] - array[1:argmax_arr]`, you could use the `np.diff` function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1S1Z7cE0E_l"
   },
   "source": [
    "# Pandas\n",
    "Until now, we have only looked at numerical data. But in real-world problems, we also have textual and categorical data. To manipulate this type of data, we will use the `pandas` library. One of the basic data structures of `pandas` is called a `DataFrame`. Generally, in a `DataFrame`, each row is a different sample and each column is a feature.\n",
    "\n",
    "For example, each row can represent a student, with columns of the ID, birthday, and gender of the student. \n",
    "\n",
    "`pandas` has a lot of possibilities of which we are going to introduce a very small subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JGYcSz82Viq"
   },
   "source": [
    "## Array Creation\n",
    "\n",
    "In addition to creating an array from lists or randomly generated data frames, we are going to use an existing dataset of house prices (you will get back to this dataset in excercise 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8pjllLVn1qGW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "4           70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "Id                                  ...                                     \n",
       "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "4          Lvl    AllPub    Corner  ...        0    NaN   NaN         NaN   \n",
       "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1        0      2    2008        WD         Normal     208500  \n",
       "2        0      5    2007        WD         Normal     181500  \n",
       "3        0      9    2008        WD         Normal     223500  \n",
       "4        0      2    2006        WD        Abnorml     140000  \n",
       "5        0     12    2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv\n",
    "df = pd.read_csv('../datasets/house_train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "LZZwdRpn6FIf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows Names\n",
      "Int64Index([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,\n",
      "            ...\n",
      "            1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460],\n",
      "           dtype='int64', name='Id', length=1460)\n",
      "\n",
      "Columns Names\n",
      "Index(['MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Alley',\n",
      "       'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
      "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle',\n",
      "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
      "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
      "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
      "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
      "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
      "       'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageYrBlt',\n",
      "       'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
      "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'SalePrice'],\n",
      "      dtype='object')\n",
      "\n",
      "Df train shape\n",
      "(1460, 80)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRows Names\")\n",
    "print(df.index)\n",
    "print(\"\\nColumns Names\")\n",
    "print(df.columns)\n",
    "print(\"\\nDf train shape\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECFka5mE49Qo"
   },
   "source": [
    "## Indexing And Slicing\n",
    "Just like when using `numpy` you can select a subset of rows and columns. You can do it using indices or using names of the rows and columns. You can easily add a new column based on existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svkkCAff6sYZ"
   },
   "outputs": [],
   "source": [
    "print(\"\\ndf[['GrLivArea', 'SalePrice', 'BedroomAbvGr']]\")\n",
    "print(df[['GrLivArea', 'SalePrice', 'BedroomAbvGr']]) # Select  GrLivArea columns SalePrice BedroomAbvGr\n",
    "\n",
    "print(\"\\ndf.loc[3:10,['GrLivArea', 'SalePrice', 'BedroomAbvGr'] ]\")\n",
    "print(df.loc[3:10,['GrLivArea', 'SalePrice', 'BedroomAbvGr'] ])\n",
    "\n",
    "print(\"\\ndf.iloc[[3, 4, 5]]\")\n",
    "print(df.iloc[[3, 4, 5]])\n",
    "print(\"\\ndf.iloc[3:10,[6, 7, 8]]\")\n",
    "print(df.iloc[3:10,[6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkqshRV-No7E"
   },
   "outputs": [],
   "source": [
    "individual_df = pd.DataFrame(np.array([np.random.randint(2000000, 3000000,50), np.random.uniform(1.50, 1.70, size = 50), np.random.uniform(45, 90, size = 50)]).transpose(), columns=['ID','Height','Weight'])\n",
    "\n",
    "individual_df[\"BMI\"] = individual_df[\"Weight\"] / individual_df[\"Height\"].pow(2)\n",
    "print(\"\\nIndividual DF\")\n",
    "print(individual_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyo4hxsp5TKm"
   },
   "source": [
    "# Basic Statistics\n",
    "`pandas` provides different statistical functions over `DataFrame`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ho-eBIBt9FQI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Median of the SalePrice column\n",
      "163000.0\n",
      "\n",
      "Selecting rows by condition\n",
      "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "Id                                                                    \n",
      "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "3           60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "5           60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "7           20       RL         75.0    10084   Pave   NaN      Reg   \n",
      "\n",
      "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
      "Id                                  ...                                     \n",
      "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
      "3          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "5          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
      "7          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
      "\n",
      "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "Id                                                             \n",
      "1        0      2    2008        WD         Normal     208500  \n",
      "2        0      5    2007        WD         Normal     181500  \n",
      "3        0      9    2008        WD         Normal     223500  \n",
      "5        0     12    2008        WD         Normal     250000  \n",
      "7        0      8    2007        WD         Normal     307000  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMedian of the SalePrice column\")\n",
    "print(df.SalePrice.median())\n",
    "\n",
    "print(\"\\nSelecting rows by condition\")\n",
    "median_price = df.SalePrice.median()\n",
    "print(df[df.SalePrice > median_price].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8lEIqi8CDNk"
   },
   "source": [
    "## Group-by\n",
    "\n",
    "When working with data that contains also a categorical feature, we are often interested in performing some kind of calculation over all rows containing the same categorical value. For example, given a data frame of student grades for different courses, we can calculate the students' average grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "tvip9jGT-Oh8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Students df\n",
      "    Name         Course  Grade\n",
      "0   Omer          Intro     95\n",
      "1    Avi           Infi     86\n",
      "2    Avi           Infi     82\n",
      "3    Avi  Probabilistic     81\n",
      "4  Zohar       Linearit     90\n",
      "\n",
      "\n",
      "Calculate average by student and by course\n",
      "      Name         Course      Grade\n",
      "0      Avi           Infi  88.400000\n",
      "1      Avi          Intro  90.000000\n",
      "2      Avi       Linearit  93.500000\n",
      "3      Avi  Probabilistic  81.333333\n",
      "4     Omer           Infi  91.333333\n",
      "5     Omer          Intro  88.333333\n",
      "6     Omer       Linearit  88.600000\n",
      "7     Omer  Probabilistic  92.666667\n",
      "8   Shelly           Infi  92.000000\n",
      "9   Shelly       Linearit  91.000000\n",
      "10  Shelly  Probabilistic  87.500000\n",
      "11   Zohar           Infi  87.500000\n",
      "12   Zohar          Intro  91.666667\n",
      "13   Zohar       Linearit  87.666667\n",
      "14   Zohar  Probabilistic  84.000000\n"
     ]
    }
   ],
   "source": [
    "students_df = pd.DataFrame(np.array([np.random.choice([\"Zohar\", \"Shelly\", \"Omer\", \"Avi\"],50), np.random.choice([\"Linearit\", \"Intro\", \"Infi\", \"Probabilistic\"], 50), np.random.randint(80, 101, 50)]).transpose(), columns=['Name','Course','Grade'])\n",
    "students_df[\"Grade\"] = students_df[\"Grade\"].astype(int)\n",
    "\n",
    "print(\"\\n\\nStudents df\")\n",
    "print(students_df.head())\n",
    "\n",
    "print(\"\\n\\nCalculate average by student and by course\")\n",
    "print(students_df.groupby(['Name', 'Course']).mean().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEFa78RCK1rq"
   },
   "source": [
    "## Sorting\n",
    "As in `numpy` you can sort data frame based on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "HjdZsJab-Z3J"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Omer</td>\n",
       "      <td>Probabilistic</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Avi</td>\n",
       "      <td>Probabilistic</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Zohar</td>\n",
       "      <td>Infi</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avi</td>\n",
       "      <td>Probabilistic</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Avi</td>\n",
       "      <td>Infi</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name         Course  Grade\n",
       "6    Omer  Probabilistic     80\n",
       "3     Avi  Probabilistic     81\n",
       "48  Zohar           Infi     81\n",
       "5     Avi  Probabilistic     81\n",
       "2     Avi           Infi     82"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students_df.sort_values(by='Grade').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CjuO2e5LdLD"
   },
   "source": [
    "## Executing Functions By Columns\n",
    "\n",
    "In `pandas`, you can select columns and apply functions to them. You also can apply functions by elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkRzYW7Jm1Ay"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(1, 10, (5,3)),columns=['col1','col2','col3'])\n",
    "\n",
    "print(\"\\n\\ndf\")\n",
    "print(df)\n",
    "print(\"\\nCalculate the difference between the min and the max of each column\")\n",
    "print(df.apply(lambda x: x.max() - x.min()))\n",
    "\n",
    "# Apply by element\n",
    "print(\"\\nMultiply elements by 100\")\n",
    "print(df.applymap(lambda x:x*100))\n",
    "\n",
    "print(\"\\n\\nIterate over the columns\")\n",
    "print(\"\\n-----------------------\")\n",
    "for key,value in df.iteritems():\n",
    "   print(key,value)\n",
    "\n",
    "print(\"\\n\\nIterate over the rows\")\n",
    "print(\"\\n-----------------------\")\n",
    "for row_idx,row in df.iterrows():\n",
    "   print(row_idx,row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvuu9aP6Ib-G"
   },
   "source": [
    "## Merging Data Frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51qFkcXH9c7c"
   },
   "outputs": [],
   "source": [
    "# Concatenate data frames\n",
    "import pandas as pd\n",
    "\n",
    "# Create 2 data frames\n",
    "ids_df1 = pd.DataFrame({\n",
    "        'ID': ['336097897', '32109678', '25976389', '32438509', '36790307'],\n",
    "         'name': ['Amos', 'Eran', 'Sapir', 'Amichai', 'Hadar'], \n",
    "        'gender': [\"M\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "\n",
    "ids_df2 = pd.DataFrame({\n",
    "        'ID': ['21370565', '34256798', '3908412', '326780578'],\n",
    "        'name': ['Matan', 'Gabriel', 'Anael', 'Liora'], \n",
    "        'gender': [\"M\", \"M\", \"F\", \"F\"]})\n",
    "\n",
    "print(\"\\n\\ndf1\")\n",
    "print(ids_df1)\n",
    "print(\"\\ndf2\")\n",
    "print(ids_df2)\n",
    "print(\"\\n\\nJoin the two dataframes along rows:\")\n",
    "concatenate_data = pd.concat([ids_df1, ids_df2])\n",
    "print(concatenate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthdates_id = pd.DataFrame({\n",
    "        'ID': ['336097897', '32109678', '25976389', '32438509', '36790307', '21370565', '34256798', '3908412', '326780578'],\n",
    "        'birth_year': [1995, 1996, 1993, 1994, 1997, 1991, 1994, 1992, 1996]})\n",
    "\n",
    "print(\"\\nNow join the result_data and df_exam_data along ID:\")\n",
    "pd.merge(concatenate_data, birthdates_id, on='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4N-gAa7bcLp5"
   },
   "source": [
    "## Let's Practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HflHhEFaP5ya"
   },
   "source": [
    "Let us create a table of flight companies' flights. Each row will represent a single flight and will have 3 features: city of departure, city of destination and price. \n",
    "\n",
    "Implement a function `create_flight_df` that recieves a collection of cities and creates a dataset of randomly selected flights and a price in the range of 100-400.\n",
    "\n",
    "```\n",
    "    def create_flight_df(cities_poss, nrows = 100):\n",
    "        pass\n",
    "```\n",
    "\n",
    "The output data frame must not have more than a single record for any pair of cities. There are no flights from a city to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWY63-sATsr9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_flight_df(cities, nrows = 20):\n",
    "    df = pd.DataFrame([], columns=[\"Departure\", \"Destination\", \"Price\"])\n",
    "    \n",
    "    while df.shape[0] < nrows:\n",
    "        dep, dest = np.random.choice(cities, size=2, replace=False)\n",
    "        price = np.random.randint(100, 400)\n",
    "        \n",
    "        if not ((df[\"Departure\"] == dep) & (df[\"Destination\"] == dest)).any():\n",
    "            df = df.append({\"Departure\": dep, \"Destination\": dest, \"Price\": price}, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "cities = [\"Beijing\", \"Moscow\", \"New-York\", \"Tokyo\", \"Paris\", \"Cairo\", \"Santiago\", \"Lima\", \"Kinshasa\", \"Singapore\", \n",
    "          \"New-Delhi\", \"London\", \"Ankara\", \"Nairobi\", \"Ottawa\", \"Seoul\", \"Tehran\", \"Guatemala\", \"Caracas\", \"Vienna\"]\n",
    "\n",
    "flights = create_flight_df(cities)\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItISmB4RYpcJ"
   },
   "source": [
    "As there are pairs of cities with no direct flight between them, let us find the pairs of cities that have a single connection flight between them and calculate the total price of the flgihts. To do so merge the two data frames. This operation is often referred to as \"joining\" with the options of inner, outer, left, right and cross joining. For more about merging `pandas` data frames read the [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvJjgHEkQq6g"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(flights, flights, left_on=[\"Destination\"], right_on=[\"Departure\"], how=\"inner\")\n",
    "df = df[df.Departure_x != df.Destination_y]\n",
    "df[\"Total_Price\"] = df[\"Price_x\"] + df[\"Price_y\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data frame with all flights of no connection and single connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights.append(df[[\"Departure_x\", \"Destination_y\", \"Total_Price\"]]\\\n",
    "                         .rename(columns={\"Departure_x\":\"Departure\", \"Destination_y\":\"Destination\", \"Total_Price\":\"Price\"}))\n",
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "il0mLoEzhi6_"
   },
   "source": [
    "Since now we might have more than one way to flight between each pair of cities, let us find the cheapest flight option, with one connection, between two cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYli93a6bMjB"
   },
   "outputs": [],
   "source": [
    "min_by_group = df.groupby([\"Departure_x\", \"Destination_y\"], as_index=False)[\"Total_Price\"].min()\n",
    "min_by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI2CrtB5irgn"
   },
   "source": [
    "And if we want to know on average what is the most expensive city to fly to then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUdokeBWiq1V"
   },
   "outputs": [],
   "source": [
    "mean_by_dest = min_by_group.groupby(\"Destination_y\")[\"Total_Price\"].mean()\n",
    "expensive_city = mean_by_dest.idxmax()\n",
    "expensive_city"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab-backround-numpy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
